\documentclass[a4paper]{article}
\usepackage{url}
\usepackage[margin=1in]{geometry}
\newcommand{\breview}{\begin{quotation}\begin{bf}\noindent}
\newcommand{\ereview}{\end{bf}\end{quotation}}
\newcommand{\reviewbullet}[1]{\breview \begin{itemize}\item #1 \end{itemize}\ereview}
\begin{document}

Dear editors:

We have attached a revised version of our manuscript ``A simple null model for inferences from network enrichment analysis'', and a diff
against our original manuscript. We have also answered the reviewer's comments
below.

In general, by reading the reviewers comments, we feel that we failed to deliver the purpose of the manuscript to the reviewer, who indeed appears to have misunderstood what we are aiming at with our manuscript. We have hence added clarifications to the introduction and the discussion. We hope that this will make the story even more interesting.

Yours Sincerely,\\[1.5cm]
Gustavo Jeuken and
Lukas K\"{a}ll
\\


\section*{Reviewer \#1}
\breview
Jeunken and Käll describe a method for generating a null distribution for so called ``network enrichment analyses'', which are sometimes framed as ``crosstalk'' analyses. The only data presented is showing that the method generates accurate pvalues under the null.
\medskip
As far as I can tell the work is technically correct. Their statement of the null hypothesis they are testing is sufficiently precise. I agree with the authors that their conceptualization of the problem is simpler than methods like BinoX. But I disagree that the interpretation can be assumed to be meaningful, and the authors provide no evidence.
\ereview
The reviewer points out that the manuscript only discusses the calibration of $p$ values, and never actually demonstrates the utility of such $p$ values. The reviewer even does not find the findings of the manuscript meaningful. While it is worth noting that  according to the Criteria For Publication PLOS ONE, (\url{https://journals.plos.org/plosone/s/criteria-for-publication}) perceived meaningfulness is not a publication criterion for a manuscript, lack of meaning is obviously an undesirable property of any scientific report. We have carefully rewritten the introduction to make the readers get a sense of the underlying conflict driving our manuscript. We feel ourselves limited from writing that existing methods for network enrichment analysis (NEA) produce grossly inflated statistics. We instead have tried to, in a constructive manner, described a method for deriving statistics that is natural from a users perspective. This model could be integrated into any of the currently used  models for NEA. It is an open question if one could demonstrate improved sensitivity with NEA over over-representation analysis in such implementations.

\breview
They claim that BinoX yields very inaccurate p-values. If the results yielded by the proposed method are basically the same as BinoX (in terms of ranks), then there is no major problem. But the authors state that they don’t want to get into evaluating ``performance in terms of sensitivity''. I find this disingenuous; they have to at least show how their ranked results compare to BinoX on real data and do some kind of benchmarking. This is important because I believe there is a difference in the null hypothesis stated in the current work and that used by BinoX that makes the comparison presented here unfair -- they are not testing the same thing.
\ereview

We fully agree with the reviewer that the null of BinoX is different that GeneSetDP. In fact that is the purpose of our manuscript. The reason why no sensitivity test is made is of course that there is no way to compete in sensitivity against a method with inflated statistics. If the yardstick is flawed no comparison can be made. Here we establish a fair yardstick to compare against. In our manuscript we are not trying to sell a new method for NEA, we are merely trying to convince the field that they should report statistics that makes sense to a user.

\breview
The crux is that the method proposed here focuses on the properties of the query genes; randomly sampling query genes makes the proposed method a test of whether the query genes are unusual, not necessarily specifically with respect to a particular pathway. For example, if the query contains a hub gene (assuming hubs are rare) then it might be found ``significantly'' connected to many pathways. The ``feature unlikely to occur by chance'' is that the query contains a hub gene, not that it connects to many pathways. To state it in an extreme way, in this situation biologist should skip the pathway analysis and just take note of the fact that the query includes a hub. Using the authors’ method without this insight could lead to very misleading conclusions.

\medskip

As I understand it, BinoX tries to account for these difficulties by modeling realizations of the network that retain key topological properties like node degree distribution while holding the query constant (in effect). The current authors criticize the BinoX approach, but ignore the problem entirely. A closer (but not very close) approximation of the BinoX approach might be, for the Monte Carlo method proposed here, to bias the sampling of Q’ from G such that the distribution of the node degrees of the genes in Q’ resembles the distribution of the actual query set of interest Q. In any case, I believe that the BinoX approach is not directly comparable. The relationship needs to be discussed and some demonstration of the method yielding useful and specific results is needed. If the authors cannot do this then they must remove the discussion of BinoX. Without that, and without any benchmarking, the paper is essentially about an algorithm to compute N(s), with no biological content or relevance.

\ereview

Here, we respectfully disagree with the reviewer. The reviewer's perspective do not reflect the actual use case. The typical user have used an experimental or computational method to derive a set of query genes that the user want to know if it is random, or if it is enriched in respect to a pathway database.  In this question, the introduction of a  network is not relevant more than in that it might shift the score distribution against pathways. A network may or may not help to increase the sensitivity of ORA methods, but it is better left out of the null hypothesis.  A user should not have to worry about the connectivity of individual genes. Just as the reviewer points out, there are certain hub genes that are connected to more pathways than others through any network. This will be reflected by the score distribution produced by our described methods. If the query set contains such a gene, the query is more likely to be significant against a pathway, however that is the desired property of the methods. Conversely, a query containing one or more genes not connected to any pathways is less likely to be significantly enriched. This is the nature of this type of analysis.

However, a perhaps more problematic fact is that the methods in this manuscript, just in all NEA methods, test every pathway independently for significance, and do not evaluate correlation between different pathways.
\breview


\breview
Minor: There are some typos I noted such as 'litterature' and 'posibile'.
\ereview
We updated these typos, and we also overall improved the language of the manuscript.

\end{document}
